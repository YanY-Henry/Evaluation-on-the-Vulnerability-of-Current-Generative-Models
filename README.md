# Evaluation on the Vulnerability of Current Generative Models

This is my [semester project](https://www.epfl.ch/schools/ic/education/bachelor/semester-project/) in [EPFL](https://www.epfl.ch/en/), 2024 Spring. It is a pleasure to work at [IVRL](https://www.epfl.ch/labs/ivrl/) and to be supervised by [Dr. Daichi Zhang](https://daisy-zhang.github.io) and [Prof. Sabine SÃ¼sstrunk](https://people.epfl.ch/sabine.susstrunk?lang=en).  

I use this [Google Doc](https://docs.google.com/document/d/17FoBg_gzQPILECPPPQtIu6bYfygablK54XeGSO93w_I/edit?usp=sharing) to record the progress of my semester project.


## Description

The rapid development of generative models has brought great changes in our daily life, such as large language models, diffusion models and even vision foundation models. However, are those models always safe enough to use? Will they cause harm to users, such as data leakage, generating biased results, or simply attacked or manipulated by attackers?

With the rapid development of Large Language Model (LLM), the concept of "jailbreak" has become popular. We would like to first study the existing attacks against LLM and eventually propose our own method to make current LLM generate illegal or harmful content.

In this project, we are interested in the safety problems of current generative models, especially LLMs, and aim to evaluate how vulnerable they are.  


## Key Questions

1. Data Leakage: since the generatve models could access to large-scale training data as well as the user input data, will it cause data leakage when genereating results?
1. Biased Results: will the generated results be fair enough or just a biased view of trained generative models.
1. Attack by users: can we perturbate or attack target generative models to make it generating wrong or desired manipulated results?


## Timeline

|**Week**|**Planned Work**|
|:-------:|:---|
|1|Set up the cluster and environment required for the project.|
|2 & 3|Experiment extensively with existing attack methods on current models and test for effectiveness.|
|4|Determine the target models and technical baseline.|
|5 & 6 & 7|Perform preliminary implementation of existing ideas and compare the experimental results. Filter and define the final technology path.|
|***TBA***|***Midterm presentation***|
|8 & 9|Work on our own idea theoretically. Present a complete idea of the attack, initially explaining or verifying its feasibility.|
|10 & 11|Implement our ideas technically. Keep trying on the models and constantly refine our own attack methods.|
|12 & 13|Attack the models with our own methods, collect the experimental data and compare with existing methods.|
|14|Complete the first draft of the thesis report (with background, motivation, etc. and without technical details, experimental information, etc.).|
|***June 07 Friday***|***Final report due***|
|***TBA***|***Final representation***|
* *This part could change at any time.*
